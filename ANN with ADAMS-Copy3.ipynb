{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23c652d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10000)\n",
      "------------------------------------------\n",
      "Finished Epoch 1 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #1 is: 2.1211295785711632\n",
      "Number of missclassified: 6328 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 2 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #2 is: 1.689204126134974\n",
      "Number of missclassified: 5580 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 3 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #3 is: 1.466459157744369\n",
      "Number of missclassified: 4749 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 4 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #4 is: 1.2922696946085852\n",
      "Number of missclassified: 4299 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 5 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #5 is: 1.2257809613605182\n",
      "Number of missclassified: 4071 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 6 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #6 is: 1.1935985688245505\n",
      "Number of missclassified: 3936 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 7 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #7 is: 1.172741053371071\n",
      "Number of missclassified: 3873 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 8 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #8 is: 1.1573589686983312\n",
      "Number of missclassified: 3815 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 9 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #9 is: 1.1450601316285158\n",
      "Number of missclassified: 3771 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 10 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #10 is: 1.1346554897983876\n",
      "Number of missclassified: 3728 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 11 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #11 is: 1.1256905816957985\n",
      "Number of missclassified: 3695 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "Finished Epoch 12 of 100\n",
      "\n",
      "\n",
      "Global Error for Epoch #12 is: 1.117820122475409\n",
      "Number of missclassified: 3668 out of 10000\n",
      "------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SEYFUL~1\\AppData\\Local\\Temp/ipykernel_17512/1100838756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;31m# Bias corrected v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mv_W_2_cor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_W_2\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[0mv_W_3_cor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_W_3\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mv_W_4_cor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_W_4\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This copy was created to TEST converting the number of neurons into variables.\n",
    "# Output: Successfully changed constants to neurons_1,2,3. \n",
    "# Issues: Not converging as it used to before. I think it requires hyperparameter tuning \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_train = pd.read_csv('mnist_train.csv')\n",
    "\n",
    "train = df_train.to_numpy()\n",
    "train = train.T\n",
    "\n",
    "train_labels = train[0, :10000]\n",
    "train_data = train[1:, :10000]\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "# Initialization\n",
    "num_of_input_neurons, num_of_train = train_data.shape\n",
    "\n",
    "neurons_1 = 50\n",
    "neurons_2 = 50\n",
    "neurons_3 = 10\n",
    "\n",
    "W_2 = np.random.normal(loc=0.0, scale=np.sqrt(2 / 784), size=(neurons_1, 784))\n",
    "W_3 = np.random.normal(loc=0.0, scale=np.sqrt(2 / 784), size=(neurons_2, neurons_1))\n",
    "W_4 = np.random.normal(loc=0.0, scale=np.sqrt(2 / 784), size=(neurons_3, neurons_2))\n",
    "\n",
    "b_2 = np.zeros(neurons_1)\n",
    "b_3 = np.zeros(neurons_2)\n",
    "b_4 = np.zeros(neurons_3)\n",
    "\n",
    "dCdW_2_store = np.zeros((neurons_1, num_of_input_neurons))\n",
    "dCdW_3_store = np.zeros((neurons_2, neurons_1))\n",
    "dCdW_4_store = np.zeros((neurons_3, neurons_2))\n",
    "\n",
    "dCdb_2_store = np.zeros(neurons_1)\n",
    "dCdb_3_store = np.zeros(neurons_2)\n",
    "dCdb_4_store = np.zeros(neurons_3)\n",
    "\n",
    "C_store = 0\n",
    "C_epoch = np.array([])\n",
    "\n",
    "# ADAM m Parameter\n",
    "m_W_2 = np.zeros((neurons_1, num_of_input_neurons))\n",
    "m_W_3 = np.zeros((neurons_2, neurons_1))\n",
    "m_W_4 = np.zeros((neurons_3, neurons_2))\n",
    "\n",
    "m_b_2 = np.zeros(neurons_1)\n",
    "m_b_3 = np.zeros(neurons_2)\n",
    "m_b_4 = np.zeros(neurons_3)\n",
    "\n",
    "# ADAM v Parameter\n",
    "v_W_2 = np.zeros((neurons_1, num_of_input_neurons))\n",
    "v_W_3 = np.zeros((neurons_2, neurons_1))\n",
    "v_W_4 = np.zeros((neurons_3, neurons_2))\n",
    "\n",
    "v_b_2 = np.zeros(neurons_1)\n",
    "v_b_3 = np.zeros(neurons_2)\n",
    "v_b_4 = np.zeros(neurons_3)\n",
    "\n",
    "# ADAM Timestep\n",
    "time = 0\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "step = 0.0001  # alpha = step\n",
    "epoch = 0\n",
    "batch_size = 20\n",
    "total_epochs = 100\n",
    "\n",
    "# ADAM parameters\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "epsilon = 1.e-8\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "###################################################FUNCTIONS###################################################\n",
    "###############################################################################################################\n",
    "\n",
    "def ReLu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    # We gotta normalize a_4 before softmax, since exp can overflow for large numbers\n",
    "    z -= max(z)\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "\n",
    "def grad_ReLu(z):\n",
    "    return np.heaviside(z, 0)\n",
    "\n",
    "\n",
    "def calc_error(a_out, true_val):\n",
    "    t = np.zeros(10)\n",
    "    t[true_val] = 1\n",
    "\n",
    "    C = -np.log(a_out[true_val])\n",
    "    return C, t\n",
    "\n",
    "\n",
    "def forward_prop(W_2, W_3, W_4, b_2, b_3, b_4, a_in):\n",
    "    z_2 = W_2 @ a_in + b_2\n",
    "    a_2 = ReLu(z_2)\n",
    "\n",
    "    z_3 = W_3 @ a_2 + b_3\n",
    "    a_3 = ReLu(z_3)\n",
    "\n",
    "    z_4 = W_4 @ a_3 + b_4\n",
    "    a_4 = ReLu(z_4)\n",
    "\n",
    "    a_out = softmax(a_4)\n",
    "    return a_2, a_3, a_4, a_out, z_2, z_3, z_4\n",
    "\n",
    "\n",
    "def back_prop(a_in, a_2, a_3, a_4, a_out, z_2, z_3, z_4, t, W_2, W_3, W_4):\n",
    "    del_4 = grad_ReLu(z_4) * (a_out - t)\n",
    "    dCdW_4 = del_4.reshape(len(del_4),1)@a_3.reshape(1,len(a_3))\n",
    "    dCdb_4 = del_4\n",
    "\n",
    "    del_3 = grad_ReLu(z_3).reshape(len(z_3),1) * (W_4.T@del_4.reshape(len(del_4),1))\n",
    "    dCdW_3 = del_3.reshape(len(del_3),1)@a_2.reshape(1,len(a_2))\n",
    "    dCdb_3 = del_3\n",
    "\n",
    "    del_2 = grad_ReLu(z_2).reshape(len(z_2),1) * (W_3.T@del_3.reshape(len(del_3),1))\n",
    "    dCdW_2 = del_2.reshape(len(del_2),1)@a_in.reshape(1,len(a_in))\n",
    "    dCdb_2 = del_2\n",
    "    return dCdW_4, dCdW_3, dCdW_2, dCdb_4, dCdb_3, dCdb_2\n",
    "\n",
    "\n",
    "def store_grad(dCdW_4, dCdW_3, dCdW_2, dCdb_4, dCdb_3, dCdb_2, dCdW_4_store, dCdW_3_store, dCdW_2_store, dCdb_4_store,\n",
    "               dCdb_3_store, dCdb_2_store, ):\n",
    "    dCdW_4_store += dCdW_4\n",
    "    dCdW_3_store += dCdW_3\n",
    "    dCdW_2_store += dCdW_2\n",
    "\n",
    "    dCdb_4_store += dCdb_4\n",
    "    dCdb_3_store += dCdb_3[:,0]\n",
    "    dCdb_2_store += dCdb_2[:,0]\n",
    "\n",
    "    return dCdW_4_store, dCdW_3_store, dCdW_2_store, dCdb_4_store, dCdb_3_store, dCdb_2_store\n",
    "\n",
    "\n",
    "def update_grad(dCdW_4_store, dCdW_3_store, dCdW_2_store, dCdb_4_store,\n",
    "                dCdb_3_store, dCdb_2_store, batch_size):\n",
    "    dCdW_4_store = dCdW_4_store / batch_size\n",
    "    dCdW_3_store = dCdW_3_store / batch_size\n",
    "    dCdW_2_store = dCdW_2_store / batch_size\n",
    "\n",
    "    dCdb_4_store = dCdb_4_store / batch_size\n",
    "    dCdb_3_store = dCdb_3_store / batch_size\n",
    "    dCdb_2_store = dCdb_2_store / batch_size\n",
    "\n",
    "    return dCdW_4_store, dCdW_3_store, dCdW_2_store, dCdb_4_store, dCdb_3_store, dCdb_2_store\n",
    "\n",
    "\n",
    "def update_weight_bias(W_2, W_3, W_4, b_2, b_3, b_4, dCdW_4_store, dCdW_3_store, dCdW_2_store, dCdb_4_store,\n",
    "                       dCdb_3_store, dCdb_2_store, step):\n",
    "    W_4 = W_4 - step * dCdW_4_store\n",
    "    W_3 = W_3 - step * dCdW_3_store\n",
    "    W_2 = W_2 - step * dCdW_2_store\n",
    "\n",
    "    b_4 = b_4 - step * dCdb_4_store\n",
    "    b_3 = b_3 - step * dCdb_3_store\n",
    "    b_2 = b_2 - step * dCdb_2_store\n",
    "\n",
    "    return W_2, W_3, W_4, b_2, b_3, b_4\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "###################################################FUNCTIONS###################################################\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "for i in range(0, total_epochs):  # Total epochs\n",
    "    C_epoch = np.append(C_epoch, 0)\n",
    "\n",
    "    for j in range(0, int(num_of_train / batch_size)):\n",
    "\n",
    "        for k in range(0, batch_size):\n",
    "            a_in = train_data[:, int(j * batch_size + k)] / 255\n",
    "            true_val = train_labels[int(j * batch_size + k)]\n",
    "\n",
    "            a_2, a_3, a_4, a_out, z_2, z_3, z_4 = forward_prop(W_2, W_3, W_4, b_2, b_3, b_4, a_in)\n",
    "            C, t = calc_error(a_out, true_val)\n",
    "            dCdW_4, dCdW_3, dCdW_2, dCdb_4, dCdb_3, dCdb_2 = back_prop(a_in, a_2, a_3, a_4, a_out, z_2, z_3, z_4, t,\n",
    "                                                                       W_2, W_3, W_4)\n",
    "            dCdW_4_store, dCdW_3_store, dCdW_2_store, dCdb_4_store, dCdb_3_store, dCdb_2_store = store_grad(dCdW_4,\n",
    "                                                                                                            dCdW_3,\n",
    "                                                                                                            dCdW_2,\n",
    "                                                                                                            dCdb_4,\n",
    "                                                                                                            dCdb_3,\n",
    "                                                                                                            dCdb_2,\n",
    "                                                                                                            dCdW_4_store,\n",
    "                                                                                                            dCdW_3_store,\n",
    "                                                                                                            dCdW_2_store,\n",
    "                                                                                                            dCdb_4_store,\n",
    "                                                                                                            dCdb_3_store,\n",
    "                                                                                                            dCdb_2_store)\n",
    "            C_store = C_store + C\n",
    "\n",
    "        dCdW_4_store, dCdW_3_store, dCdW_2_store, dCdb_4_store, dCdb_3_store, dCdb_2_store = update_grad(dCdW_4_store,\n",
    "                                                                                                         dCdW_3_store,\n",
    "                                                                                                         dCdW_2_store,\n",
    "                                                                                                         dCdb_4_store,\n",
    "                                                                                                         dCdb_3_store,\n",
    "                                                                                                         dCdb_2_store,\n",
    "                                                                                                         batch_size)\n",
    "        #####################  ADAM OPTIMIZER  #####################\n",
    "        time = time + 1\n",
    "\n",
    "        # UPDATE m\n",
    "        m_W_2 = m_W_2 * beta_1 + (1 - beta_1) * dCdW_2_store\n",
    "        m_W_3 = m_W_3 * beta_1 + (1 - beta_1) * dCdW_3_store\n",
    "        m_W_4 = m_W_4 * beta_1 + (1 - beta_1) * dCdW_4_store\n",
    "\n",
    "        m_b_2 = m_b_2 * beta_1 + (1 - beta_1) * dCdb_2_store\n",
    "        m_b_3 = m_b_3 * beta_1 + (1 - beta_1) * dCdb_3_store\n",
    "        m_b_4 = m_b_4 * beta_1 + (1 - beta_1) * dCdb_4_store\n",
    "\n",
    "        # Update v\n",
    "        v_W_2 = v_W_2 * beta_2 + (1 - beta_2) * np.square(dCdW_2_store)\n",
    "        v_W_3 = v_W_3 * beta_2 + (1 - beta_2) * np.square(dCdW_3_store)\n",
    "        v_W_4 = v_W_4 * beta_2 + (1 - beta_2) * np.square(dCdW_4_store)\n",
    "\n",
    "        v_b_2 = v_b_2 * beta_2 + (1 - beta_2) * np.square(dCdb_2_store)\n",
    "        v_b_3 = v_b_3 * beta_2 + (1 - beta_2) * np.square(dCdb_3_store)\n",
    "        v_b_4 = v_b_4 * beta_2 + (1 - beta_2) * np.square(dCdb_4_store)\n",
    "\n",
    "        # Bias corrected m\n",
    "        m_W_2_cor = m_W_2 / (1 - (beta_1 ** time))\n",
    "        m_W_3_cor = m_W_3 / (1 - (beta_1 ** time))\n",
    "        m_W_4_cor = m_W_4 / (1 - (beta_1 ** time))\n",
    "\n",
    "        m_b_2_cor = m_b_2 / (1 - (beta_1 ** time))\n",
    "        m_b_3_cor = m_b_3 / (1 - (beta_1 ** time))\n",
    "        m_b_4_cor = m_b_4 / (1 - (beta_1 ** time))\n",
    "\n",
    "        # Bias corrected v\n",
    "        v_W_2_cor = v_W_2 / (1 - (beta_2 ** time))\n",
    "        v_W_3_cor = v_W_3 / (1 - (beta_2 ** time))\n",
    "        v_W_4_cor = v_W_4 / (1 - (beta_2 ** time))\n",
    "\n",
    "        v_b_2_cor = v_b_2 / (1 - (beta_2 ** time))\n",
    "        v_b_3_cor = v_b_3 / (1 - (beta_2 ** time))\n",
    "        v_b_4_cor = v_b_4 / (1 - (beta_2 ** time))\n",
    "\n",
    "        # UPDATE WEIGHT AND BIAS\n",
    "        W_2 = W_2 - step * m_W_2_cor / (np.sqrt(v_W_2_cor) + epsilon)\n",
    "        W_3 = W_3 - step * m_W_3_cor / (np.sqrt(v_W_3_cor) + epsilon)\n",
    "        W_4 = W_4 - step * m_W_4_cor / (np.sqrt(v_W_4_cor) + epsilon)\n",
    "\n",
    "        b_2 = b_2 - step * m_b_2_cor / (np.sqrt(v_b_2_cor) + epsilon)\n",
    "        b_3 = b_3 - step * m_b_3_cor / (np.sqrt(v_b_3_cor) + epsilon)\n",
    "        b_4 = b_4 - step * m_b_4_cor / (np.sqrt(v_b_4_cor) + epsilon)\n",
    "\n",
    "        # W_2, W_3, W_4, b_2, b_3, b_4 = update_weight_bias(W_2, W_3, W_4, b_2, b_3, b_4, dCdW_4_store, dCdW_3_store,\n",
    "        #                                                  dCdW_2_store, dCdb_4_store, dCdb_3_store, dCdb_2_store, step)\n",
    "\n",
    "        C_epoch[i] += C_store\n",
    "\n",
    "        # Empty stores for next batch\n",
    "        dCdW_2_store = np.zeros((neurons_1, num_of_input_neurons))\n",
    "        dCdW_3_store = np.zeros((neurons_2, neurons_1))\n",
    "        dCdW_4_store = np.zeros((neurons_3, neurons_2))\n",
    "\n",
    "        dCdb_2_store = np.zeros(neurons_1)\n",
    "        dCdb_3_store = np.zeros(neurons_2)\n",
    "        dCdb_4_store = np.zeros(neurons_3)\n",
    "\n",
    "        C_store = 0\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    pred = np.array([], dtype=int)\n",
    "    for cnt in range(0, num_of_train):\n",
    "        a_in = train_data[:, cnt] / 255\n",
    "        a_2, a_3, a_4, a_out, z_2, z_3, z_4 = forward_prop(W_2, W_3, W_4, b_2, b_3, b_4, a_in)\n",
    "        pred = np.append(pred, np.argmax(a_out))\n",
    "\n",
    "    print('------------------------------------------')\n",
    "    print(\"Finished Epoch \" + str(epoch) + \" of \" + str(total_epochs))\n",
    "    print('\\n')\n",
    "    print(\"Global Error for Epoch #\" + str(epoch) + ' is: ' + str(C_epoch[i] / num_of_train))\n",
    "    print(\"Number of missclassified: \" + str(np.count_nonzero(pred != train_labels)) + \" out of \" + str(num_of_train))\n",
    "    print('------------------------------------------')\n",
    "    print('\\n')\n",
    "\n",
    "    # Stopping once we reach n% of misclassifications (60,000 training data)\n",
    "    npercent = 0.03\n",
    "    if (i > 0) & (np.count_nonzero(pred != train_labels) < npercent * 10000):\n",
    "        print('Reached ' + str(npercent * 100) + ' percent missclassifications. Stopping...')\n",
    "        break\n",
    "\n",
    "plt.plot(np.array(range(0, i + 1)) + 1, C_epoch / num_of_train, marker='o', markersize=7.5, markerfacecolor='r')\n",
    "plt.grid()\n",
    "plt.title('Epoch vs. Global Error')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56dbd4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(pred != train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf1f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84357dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SEYFUL~1\\AppData\\Local\\Temp/ipykernel_17512/1915025023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mnist_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('mnist_test.csv')\n",
    "test = df_test.to_numpy()\n",
    "test = test.T\n",
    "test_labels = test[0,:]\n",
    "test_data = test[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING THE MODEL\n",
    "\n",
    "dummy, num_of_test = test_data.shape\n",
    "predictions = np.array([],dtype = int)\n",
    "\n",
    "for cnt in range(0,num_of_test):\n",
    "    a_in = test_data[:,cnt]/255\n",
    "    a_2, a_3, a_4, a_out, z_2, z_3, z_4 = forward_prop(W_2, W_3, W_4, b_2, b_3, b_4, a_in)\n",
    "    predictions = np.append(predictions,np.argmax(a_out))\n",
    "    \n",
    "\n",
    "num_of_missclassified = np.count_nonzero(predictions != test_labels)\n",
    "print(\"Number of missclassified from Test Data: \" + str(num_of_missclassified) + \" out of \" + str(num_of_test))\n",
    "print('\\n')\n",
    "print('Error rate: ' + str(100 - 100*(num_of_test-num_of_missclassified)/num_of_test) + ' percent'   )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
